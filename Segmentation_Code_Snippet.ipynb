{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Code Snippet\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Missing Value Per Column\n",
    "\n",
    "def missing_values_per_column(df): \n",
    "    \"\"\"\n",
    "    Look for missing values(np.nan) in all the columns.\n",
    "\n",
    "    Parameters |\n",
    "\n",
    "    df : Required dataframe \n",
    "\n",
    "    Returns \n",
    "    ---------\n",
    "    Returns a dataframe with the missing value count and missing pcrcent.\n",
    "    \"\"\"\n",
    "    missingTable = pd.DataFrame() \n",
    "    missingTable['MissingCount'] = df.isnull().sum().sort_values(ascending=False) \n",
    "    missingTable['MissingPercent'] = 100 * df.isnull().sum() / len(df) \n",
    "\n",
    "    return missingTable\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN Imputation\n",
    "\n",
    "def knn_imputation(df):\n",
    "    \"\"\"\n",
    "    Replace NaN with KNN model.\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    df: DataFrame containing the cols\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "\n",
    "    DataFrame where the missing values have been imputed.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df_x = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    imputer = KNNImputer(n_neighbors=s)\n",
    "    df_y = pd.DataFrame(imputer.fit_transform(df_x), columns=df_x.columns)\n",
    "    num_data = scaler.inverse_transform(df_y)\n",
    "    num_data = pd.DataFrame(num_data, columns=df_y.columns)\n",
    "    return num_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#VIF Analysis\n",
    "\n",
    "def vif_operation(df, cols):\n",
    "    if cols:\n",
    "        df.drop(cols,axis=1,inplace=True)\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Features\"] = df.columns\n",
    "\n",
    "    #calculating VIF for each feature\n",
    "    vif_data[\"VIF\"] = [VIF(df.values, i)for i in range(len(df.columns))]\n",
    "    vif_data = vif_data.sort_values(by='VIF', ascending=False, ignore_index=True)\n",
    "    cols_tuple =tuple(cols)\n",
    "    d[cols_tuple] = vif_data\n",
    "    return vif_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Prediction code\n",
    "\n",
    "y = data[ 'Profitable']\n",
    "X = data.drop(['Profitable'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "# train model\n",
    "model = RandomForestClassifier(n_estimators=860, min_samples_split=15, \n",
    "                                min_samples_leaf-30, max_samples-1608,\n",
    "                                max_features=\"10g2\", max_depth=28,\n",
    "                                criterion='entropy', bootstrap=True\n",
    "                                class_weight=\"balanced_subsample\")\n",
    "model. fit(X_train, y_train)\n",
    "# generate precision-recall table\n",
    "y_test_probs = model.predict_proba(X_test)[:,1]\n",
    "# Containers for true positive / false positive rates\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "# Define probability thresholds to use, between 0 and 1\n",
    "probability_thresholds = np.arange(0, 1, .01)\n",
    "# Find true positive / false positive rate for each threshold\n",
    "for p in probability_thresholds:\n",
    "        y_test_preds = [0 if prob <= p else 1 for prob in y_test_probs]\n",
    "        precision = precision_score(y_test, y_test_preds)\n",
    "        recall = recall_score(y_test, y_test_preds)\n",
    "        f1 = f1_score(y_test, y_test_preds)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores. append(f1)\n",
    "\n",
    "df = pd.DataFrame({\"Prob_Threshold\" :probability_thresholds, 'Precision':precision_scores,\n",
    "                    \"Recall\":recall_scores, 'F1_Score':f1_scores})\n",
    "train_preds = np.where(model.predict_proba(X_train)[:,1] >= .45, 1, 8)\n",
    "test_preds = np.where(model.predict_proba(X_test)[:,1] >= 8.45, 1, 8)\n",
    "\n",
    "# generate classification report\n",
    "classification_report(y_train, train_preds, y_test, test_preds)\n",
    "# plat confusion matrix\n",
    "plot_confusion_mat(y_test, test_preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Hyper Parameter Tuning\n",
    "\n",
    "y = data[\"Profitable\"]\n",
    "X = data.drop(['Profitable'] , axis=1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size = 6.2, randos_state = 42, stratify = y)\n",
    "Model = RandomForestClassifier()\n",
    "param_grid = [\n",
    "            {\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"max_depth\": [5,10,15,20,25,30,None],\n",
    "                \"max_features\": [\"auto\", \"log2\"],\n",
    "                \"min_samples_leaf\": np.arange(10,109,18),\n",
    "                \"min_samples_split\": np.arange(5, 50, 5),\n",
    "                \"n_estimators\": [100,200, 400, 600, 800, 1000, 1200],\n",
    "                \"class_weight\" : [\"balanced”, “balanced_subsample\", None],\n",
    "                \"max_samples\" : np.arange(109, 2009, 180)\n",
    "            }\n",
    "]\n",
    "\n",
    "hp = RandomizedSearchCV(estimator = Model, param_distributions = paras_grid, n_iter = 100,  \n",
    "                        cv = 3, verbose=True, random_state=42, n_jobs = -1, scoring=\"roc_auc\")\n",
    "best_hp= hp.Fit(X_train, y_train)\n",
    "best_hp.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}